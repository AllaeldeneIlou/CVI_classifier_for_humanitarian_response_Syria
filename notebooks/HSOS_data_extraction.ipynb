{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347ee780-58b8-426a-9cb9-ab45108880ba",
   "metadata": {},
   "source": [
    "# Renaming Files with the same pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307967d-5283-423b-abaf-01e29d13acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466d103-072e-4697-8bd0-d00831c18d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def project_excel_files(directory):\n",
    "    files_format_region_end = []\n",
    "    files_format_dataset = []\n",
    "    \n",
    "    # Run through all files in folder\n",
    "    for filename in os.listdir(directory):\n",
    "        if \"REACH_SYR_HSOS_Dataset\" in filename:\n",
    "            files_format_dataset.append(filename)\n",
    "        else:\n",
    "            files_format_region_end.append(filename)\n",
    "            \n",
    "    return files_format_region_end, files_format_dataset\n",
    "\n",
    "# Directory path\n",
    "directory = \"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/Uni-1\"\n",
    "format_region_end, format_region_first = project_excel_files(directory)\n",
    "\n",
    "# Date Mapper\n",
    "month_map = {\n",
    "    \"January\": \"01\", \"February\": \"02\", \"March\": \"03\",\n",
    "    \"April\": \"04\", \"May\": \"05\", \"June\": \"06\",\n",
    "    \"July\": \"07\", \"August\": \"08\", \"September\": \"09\",\n",
    "    \"October\": \"10\", \"November\": \"11\", \"December\": \"12\"\n",
    "}\n",
    "\n",
    "new_filenames_region_end = []\n",
    "new_filenames_region_first = []\n",
    "\n",
    "# Format for file with region end\n",
    "for filename in format_region_end:\n",
    "    filename = filename.replace(\".xlsx\", \"\")\n",
    "    parts = filename.split(\"_\")\n",
    "    date = parts[-1]\n",
    "    region = parts[-3]\n",
    "    \n",
    "    # Get month & year\n",
    "    month = ''.join(filter(str.isalpha, date))\n",
    "    year = ''.join(filter(str.isdigit, date))\n",
    "    format_date = f\"{month_map[month]}_{year}\"\n",
    "    \n",
    "    new_filename = f\"HSOS_{region}_Dataset_{format_date}.xlsx\"\n",
    "    new_filenames_region_end.append(new_filename)\n",
    "\n",
    "# Format for file with region first\n",
    "for filename in format_region_first:\n",
    "    parts = filename.split(\"_\")\n",
    "    date = parts[-2]\n",
    "    region = parts[-1].replace(\".xlsx\", \"\")\n",
    "    \n",
    "    # Get month & year\n",
    "    month = ''.join(filter(str.isalpha, date))\n",
    "    year = ''.join(filter(str.isdigit, date))\n",
    "    format_date = f\"{month_map[month]}_{year}\"\n",
    "    \n",
    "    new_filename = f\"HSOS_{region}_Dataset_{format_date}.xlsx\"\n",
    "    new_filenames_region_first.append(new_filename)\n",
    "\n",
    "# Rename files in 'format_region_end' group\n",
    "for old_filename, new_filename in zip(format_region_end, new_filenames_region_end):\n",
    "    old_filepath = os.path.join(directory, old_filename)\n",
    "    new_filepath = os.path.join(directory, new_filename)\n",
    "    os.rename(old_filepath, new_filepath)\n",
    "    print(f\"Renamed: {old_filename} --> {new_filename}\")\n",
    "\n",
    "# Rename files in 'format_region_first' group\n",
    "for old_filename, new_filename in zip(format_region_first, new_filenames_region_first):\n",
    "    old_filepath = os.path.join(directory, old_filename)\n",
    "    new_filepath = os.path.join(directory, new_filename)\n",
    "    os.rename(old_filepath, new_filepath)\n",
    "    print(f\"Renamed: {old_filename} --> {new_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195dd05-d5e9-4041-8ed3-7e34f65e6e74",
   "metadata": {},
   "source": [
    "# Read all sheets & Create df from all the sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d7077-3e96-4ee0-b40c-2211bcb53958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheet_names(file_path):\n",
    "    try:\n",
    "        # Load Excel File\n",
    "        workbook = load_workbook(file_path, read_only=True)\n",
    "        # Read Sheetnames\n",
    "        return workbook.sheetnames\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Verarbeiten der Datei {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def create_sheet_names_dataframe(directory):\n",
    "    data = []\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\".xlsx\")]\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        sheet_names = get_sheet_names(file_path)\n",
    "        if sheet_names:\n",
    "            data.append([file] + sheet_names)\n",
    "\n",
    "    # Max Sheet names\n",
    "    max_sheets = max(len(row) for row in data)\n",
    "\n",
    "    # Dynamic columnnames\n",
    "    column_names = [\"Dateiname\"] + [f\"Blattname {i}\" for i in range(1, max_sheets)]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d7310-4395-44e7-8c06-f5c7bea1e76a",
   "metadata": {},
   "source": [
    "# Extracting all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d53cee-de17-4273-948b-218a350762f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/Uni-1/\"\n",
    "e_sheet_name = \"dataset1\"\n",
    "\n",
    "# Extract columns names\n",
    "def column_ex(filepath):\n",
    "    workbook = pd.read_excel(filepath, sheet_name=e_sheet_name)\n",
    "    return list(workbook.columns)\n",
    "\n",
    "column_names = []\n",
    "\n",
    "# Maximum columns number\n",
    "max_columns = 0\n",
    "\n",
    "# Iterate through all files in folder\n",
    "for file in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, file)  \n",
    "    try:\n",
    "        columns = column_ex(file_path)\n",
    "        # Aktualisieren der maximalen Spaltenanzahl\n",
    "        max_columns = max(max_columns, len(columns))\n",
    "        column_names.append({\"File\": file, **{f\"Column_{i+1}\": col for i, col in enumerate(columns)}})\n",
    "        print(f\"Datei {file} erfolgreich\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Datei {file}: {e}\")  \n",
    "\n",
    "# all files have the max col number\n",
    "for entry in column_names:\n",
    "    # Max col number\n",
    "    file_columns = [entry.get(f\"Column_{i+1}\") for i in range(max_columns)]\n",
    "    # Nan if cols dont exist\n",
    "    file_columns += [None] * (max_columns - len(file_columns))\n",
    "    entry.update({f\"Column_{i+1}\": col for i, col in enumerate(file_columns)})\n",
    "\n",
    "# df\n",
    "df_col_names = pd.DataFrame(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371bb0f-978c-4e44-8df2-b3dbe8f58576",
   "metadata": {},
   "source": [
    "# creating comparison file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc5470-264d-49a0-a3a3-3bfb80c8bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/Columnname_Overview.csv\")\n",
    "\n",
    "data_values = df.drop(columns=[\"File\"])\n",
    "\n",
    "# Dictionary\n",
    "value_to_files = {}\n",
    "\n",
    "# Iterate df\n",
    "for col in data_values.columns:  # per column\n",
    "    for index, value in data_values[col].items():  # per row\n",
    "        if pd.notna(value):  # look at non nan values\n",
    "            if value not in value_to_files:\n",
    "                value_to_files[value] = []  \n",
    "            value_to_files[value].append(df.loc[index, \"File\"])\n",
    "\n",
    "# List of all files\n",
    "all_files = set(df[\"File\"])\n",
    "\n",
    "# Create df\n",
    "exploded_data = pd.DataFrame(\n",
    "    {file: [1 if file in files else 0 for files in value_to_files.values()] for file in all_files},\n",
    "    index=value_to_files.keys()\n",
    ")\n",
    "\n",
    "# Index and Col naming\n",
    "exploded_data.index.name = \"Value\"\n",
    "exploded_data.columns.name = \"File\"\n",
    "\n",
    "# Export\n",
    "exploded_data.to_excel(\"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/Common_col.xlsx\")\n",
    "exploded_data.to_csv(\"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/Common_col.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61817d-f378-49a5-bf7f-66d37deb35de",
   "metadata": {},
   "source": [
    "# working dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c66194-5ae9-4bfe-a32c-f172fcebf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reference file\n",
    "reference = pd.read_csv(\n",
    "    \"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/columns_from_mapping.csv\", \n",
    "    sep=\";\")\n",
    "\n",
    "# Transpose reference if necessary\n",
    "ref_columns = reference.columns  # Assuming column names are needed for comparison\n",
    "\n",
    "directory = \"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/HSOS DATA/\"\n",
    "\n",
    "# Define the function to get data\n",
    "def get_data(filepath):\n",
    "    try:\n",
    "        # Extract the last 11 characters of the file name (excluding extension)\n",
    "        file_name = os.path.basename(filepath)\n",
    "        name_column = file_name[:-5][-11:]  # Remove .xlsx and get last 11 characters\n",
    "        \n",
    "        # Read data from the Excel file\n",
    "        data = pd.read_excel(filepath, sheet_name=\"dataset1\")\n",
    "        \n",
    "        # Filter data based on reference columns\n",
    "        filtered_data = data[[col for col in data.columns if col in ref_columns]].copy()\n",
    "        \n",
    "        # Add a new column with the extracted name\n",
    "        filtered_data.loc[:, \"Name\"] = name_column\n",
    "        \n",
    "        return filtered_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Running through files and getting data\n",
    "final = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, file)\n",
    "    print(file_path)\n",
    "    if file_path.endswith(\".xlsx\"):  # Ensure only Excel files are processed\n",
    "        data = get_data(file_path)\n",
    "        if data is not None:\n",
    "            final.append(data)\n",
    "\n",
    "# Combine all the collected data\n",
    "if final:\n",
    "    df = pd.concat(final, ignore_index=True)\n",
    "    print(\"Final DataFrame created successfully.\")\n",
    "    print(df.head())  # Display a preview of the final DataFrame\n",
    "else:\n",
    "    print(\"No valid data was processed.\")\n",
    "\n",
    "df[\"Year\"] = df[\"Name\"].str.split(\"_\").str[0].astype(int)\n",
    "df[\"Month\"] = df[\"Name\"].str.split(\"_\").str[1].astype(int)\n",
    "#df[\"Region\"] = df[\"Name\"].str.split(\"_\").str[2]\n",
    "\n",
    "move_col = df.pop(\"Year\")\n",
    "df.insert(0, \"Year\", move_col)\n",
    "\n",
    "move_col = df.pop(\"Month\")\n",
    "df.insert(1, \"Month\", move_col)\n",
    "\n",
    "\n",
    "df.to_csv(\"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/Final_DF_mapped.csv\", index=False, sep=\";\")\n",
    "\n",
    "#excel export doesnt work\n",
    "#df.to_excel(\"C:/Users/caspa/OneDrive/00 DataScientist/Projekt/HSOS/final_output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
